---
layout: default1
nav: links-ml
title: Deep Learning
is_slide: 0
---
- Deep Learning Tuning Playbook
[(link)](https://github.com/google-research/tuning_playbook)
- viso.ai Blog
[(link)](https://viso.ai/blog/)


# CNN
- Convolutional Neural Networks (CNNs / ConvNets)
[(link)](https://cs231n.github.io/convolutional-networks/)
- 1×1 Convolution In Detail
[(link)](https://hackerstreak.com/1x1-convolution/)
- Comprehensive look at 1X1 Convolution
[(link)](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578)
- 6 Significant Computer Vision Problems Solved by ML
[(link)](https://heartbeat.fritz.ai/6-significant-computer-vision-problems-solved-by-ml-623eb50544c5)
- A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way
[(link)](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)
- How to Train Your ResNet
[(link)](https://myrtle.ai/how-to-train-your-resnet/)
- Convolution arithmetic tutorial
[(link)](https://theano-pymc.readthedocs.io/en/latest/tutorial/conv_arithmetic.html)
- Transposed Convolutions explained with… MS Excel!
[(link)](https://medium.com/apache-mxnet/transposed-convolutions-explained-with-ms-excel-52d13030c7e8)
- Up-sampling with Transposed Convolution
[(link)](https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0)
- CNNs from different viewpoints
[(link)](https://medium.com/impactai/cnns-from-different-viewpoints-fab7f52d159c)

# Enhancing Photos With Deep Learning
- Part 1: Overview
[(link)](https://medium.datadriveninvestor.com/enhancing-photos-with-deep-learning-part-1-an-overview-80f2dcb96849)
- Part 2: The Data
[(link)](https://python.plainenglish.io/enhancing-photos-with-deep-learning-part-2-the-data-6ffcde6439a1)
- Part 3: The Loss Function
[(link)](https://borna-ahz.medium.com/enhancing-photos-with-deep-learning-part-3-the-loss-function-28f586216b09)
- Part 4: The Model
[(link)](https://python.plainenglish.io/enhancing-photos-with-deep-learning-part-4-the-model-440ecc817d1a)
- Part 5: The Back-End
[(link)](https://python.plainenglish.io/enhancing-photos-with-deep-learning-part-5-the-back-end-9270d54f360c)
- Part 6: The Front-End
[(link)](https://python.plainenglish.io/enhancing-photos-with-deep-learning-part-6-the-front-end-bc762a770a92)

# Image Segmentation / Object Detection
- Mediapipe
[(link)](https://google.github.io/mediapipe/)
- ActionDetectionforSignLanguage
[(link)](https://github.com/nicknochnack/ActionDetectionforSignLanguage/blob/main/Action%20Detection%20Refined.ipynb)
- UNet
[(link)](https://towardsdatascience.com/u-net-b229b32b4a71)
- SemTorch - Architectures definitions for image segmentation
[(link)](https://github.com/WaterKnight1998/SemTorch)
- DE:TR: End-to-End Object Detection with Transformers
[(link)](https://github.com/facebookresearch/detr)
- Review: YOLOv3 — You Only Look Once (Object Detection)
[(link)](https://towardsdatascience.com/review-yolov3-you-only-look-once-object-detection-eab75d7a1ba6)
- R-CNN (Object Detection)
[(link)](https://medium.com/@selfouly/r-cnn-3a9beddfd55a)
- Review of Deep Learning Algorithms for Object Detection
[(link)](https://medium.com/zylapp/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852)
- Image Segmentation in 2021: Architectures, Losses, Datasets, and Frameworks
[(link)](https://neptune.ai/blog/image-segmentation-in-2020)
- Review of Deep Learning Algorithms for Image Semantic Segmentation
[(link)](https://medium.com/@arthur_ouaknine/review-of-deep-learning-algorithms-for-image-semantic-segmentation-509a600f7b57)
- R-CNN, Fast R-CNN, Faster R-CNN, YOLO — Object Detection Algorithms
[(link)](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e)
- YOLO (v3) object detector from scratch in PyTorch
[(link)](https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/)
- Image Processing with Python — Unsupervised Learning for Image Segmentation
[(link)](https://towardsdatascience.com/image-processing-with-python-unsupervised-learning-for-image-segmentation-90ebd23d91a4)
- Fastai - Video
[(link)](https://youtu.be/nG3tT31nPmQ?t=1h29m13s)
- FastFCN git
[(link)](https://github.com/wuhuikai/FastFCN)


# Misc
- Document Denoising Using Deep Learning
[(link)](https://medium.com/ai-techsystems/document-denoising-using-deep-learning-a114302b4b1f)
- Few shot learning — learning to learn from a few examples
[(link)](https://pavelkordik.medium.com/few-shot-learning-learning-to-learn-from-a-few-examples-772503c76b8e)
- Paper Explained- Vision Transformers
[(link)](https://medium.com/analytics-vidhya/vision-transformers-bye-bye-convolutions-e929d022e4ab)
- Why gradient descent doesn’t converge with unscaled features?
[(link)](https://medium.com/analytics-vidhya/why-gradient-descent-doesnt-converge-with-unscaled-features-8b7ed0c8cab6)
- Generalization in Neural Network
[(link)](https://medium.com/deep-learning-demystified/generalization-in-neural-networks-7765ee42ac23)
- Sarcasm detection in news headlines — on cAInvas
[(link)](https://aitechsystems.medium.com/sarcasm-detection-in-news-headlines-on-cainvas-7b7ed5c2b3bb)
- Contrastive Representation Learning
[(link)](https://lilianweng.github.io/lil-log/2021/05/31/contrastive-representation-learning.html)
- CLIP git
[(link)](https://github.com/OpenAI/CLIP)
- DALL·E: Creating Images from Text
[(link)](https://openai.com/blog/dall-e/)
- Image Data Labelling and Annotation — Everything you need to know
[(link)](https://towardsdatascience.com/image-data-labelling-and-annotation-everything-you-need-to-know-86ede6c684b1)
- Activation Functions — All You Need To Know!
[(link)](https://medium.com/analytics-vidhya/activation-functions-all-you-need-to-know-355a850d025e)
- Loss Functions Explained
[(link)](https://medium.com/deep-learning-demystified/loss-functions-explained-3098e8ff2b27)
- Deep Dive into Math Behind Deep Networks
[(link)](https://towardsdatascience.com/https-medium-com-piotr-skalski92-deep-dive-into-deep-networks-math-17660bc376ba)
- Everything you need to know about “Activation Functions” in Deep learning models
[(link)](https://towardsdatascience.com/everything-you-need-to-know-about-activation-functions-in-deep-learning-models-84ba9f82c253)
- Weight Initialization Techniques in Neural Networks
[(link)](https://towardsdatascience.com/weight-initialization-techniques-in-neural-networks-26c649eb3b78)
[(link)](https://ai.googleblog.com/2021/01/learning-to-reason-over-tables-from.html)
- Understanding Variational Autoencoders (VAEs)
[(link)](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73)
- Table Detection, Information Extraction and Structuring using Deep Learning
[(link)](https://nanonets.com/blog/table-extraction-deep-learning/)
- Deconvolution and Checkerboard Artifacts
[(link)](https://distill.pub/2016/deconv-checkerboard/)
- Troubleshooting Deep Neural Networks
[(link)](http://josh-tobin.com/troubleshooting-deep-neural-networks)

# Optimization Methods
- Vectorizing Gradient Descent — Multivariate Linear Regression and Python implementation
[(link)](https://medium.com/analytics-vidhya/vectorizing-gradient-descent-multivariate-linear-regression-and-python-implementation-e12758bc31b2)
- The LookAhead optimizer
[(link)](https://towardsdatascience.com/dont-look-backwards-lookahead-6bcd7ff50f93)
- New Deep Learning Optimizer, Ranger: Synergistic combination of RAdam + LookAhead for the best of both.
[(link)](https://lessw.medium.com/new-deep-learning-optimizer-ranger-synergistic-combination-of-radam-lookahead-for-the-best-of-2dc83f79a48d)
- Understanding Optimizers
[(link)](https://medium.com/deep-learning-demystified/https-medium-com-deep-learning-demystified-understanding-optimizers-313b787a69fe)
“Adam” and friends
[(link)](https://amaarora.github.io/2021/03/13/optimizers.html)
- Adam — latest trends in deep learning optimization.
[(link)](https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c)
- Various Optimization Algorithms For Training Neural Network
[(link)](https://towardsdatascience.com/optimizers-for-training-neural-network-59450d71caf6)
- Which Optimizer should I use for my Machine Learning Project?
[(link)](https://www.whattolabel.com/post/which-optimizer-should-i-use-for-my-machine-learning-project)
- Gradient Descent
[(link)](https://blog.paperspace.com/intro-to-optimization-in-deep-learning-gradient-descent/)
- Gradient Descent Algorithm — a deep dive
[(link)](https://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-cf04e8115f21)
- Intro Momentum, RMSProp and Adam
[(link)](https://blog.paperspace.com/intro-to-optimization-momentum-rmsprop-adam/)
- An overview of gradient descent optimization algorithms
[(link)](http://ruder.io/optimizing-gradient-descent/)
- BatchNorm 1
[(link)](https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c)
- BatchNorm 2
[(link)](https://gab41.lab41.org/batch-normalization-what-the-hey-d480039a9e3b)
- BatchNorm 3
[(link)](https://blog.paperspace.com/busting-the-myths-about-batch-normalization/)

